{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T21:37:19.736903Z",
     "iopub.status.busy": "2024-12-02T21:37:19.736576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: chestmnist, Num Classes: 14\n",
      "Downloading https://zenodo.org/records/10519652/files/chestmnist.npz?download=1 to /root/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82802576/82802576 [00:07<00:00, 11709328.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /root/.medmnist/chestmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:08<00:00, 62.8MB/s] \n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:01<00:00, 66.6MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 63.0MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n",
      "100%|██████████| 30.8M/30.8M [00:00<00:00, 53.5MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4130db92314d6aa0846279835112c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a639dfd2074579b5ef22d4b0ece183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training VGG16...\n",
      "[VGG16] Epoch 1/10 | Train Acc: 94.84% | Test Acc: 94.75% | AUC: 0.7293\n",
      "[VGG16] Epoch 2/10 | Train Acc: 94.90% | Test Acc: 94.80% | AUC: 0.7606\n",
      "[VGG16] Epoch 3/10 | Train Acc: 94.92% | Test Acc: 94.78% | AUC: 0.7589\n",
      "[VGG16] Epoch 4/10 | Train Acc: 94.96% | Test Acc: 94.76% | AUC: 0.7760\n",
      "[VGG16] Epoch 5/10 | Train Acc: 95.03% | Test Acc: 94.78% | AUC: 0.7725\n",
      "[VGG16] Epoch 6/10 | Train Acc: 95.31% | Test Acc: 94.65% | AUC: 0.7743\n",
      "[VGG16] Epoch 7/10 | Train Acc: 95.48% | Test Acc: 94.60% | AUC: 0.7700\n",
      "[VGG16] Epoch 8/10 | Train Acc: 95.64% | Test Acc: 94.49% | AUC: 0.7608\n",
      "[VGG16] Epoch 9/10 | Train Acc: 95.83% | Test Acc: 94.39% | AUC: 0.7541\n",
      "[VGG16] Epoch 10/10 | Train Acc: 96.09% | Test Acc: 94.30% | AUC: 0.7448\n",
      "\n",
      "Training ResNet50...\n",
      "[ResNet50] Epoch 1/10 | Train Acc: 94.84% | Test Acc: 94.76% | AUC: 0.7694\n",
      "[ResNet50] Epoch 2/10 | Train Acc: 94.91% | Test Acc: 94.80% | AUC: 0.7827\n",
      "[ResNet50] Epoch 3/10 | Train Acc: 94.95% | Test Acc: 94.80% | AUC: 0.7888\n",
      "[ResNet50] Epoch 4/10 | Train Acc: 95.05% | Test Acc: 94.68% | AUC: 0.7790\n",
      "[ResNet50] Epoch 5/10 | Train Acc: 95.22% | Test Acc: 94.61% | AUC: 0.7750\n",
      "[ResNet50] Epoch 6/10 | Train Acc: 96.21% | Test Acc: 94.28% | AUC: 0.7498\n",
      "[ResNet50] Epoch 7/10 | Train Acc: 96.95% | Test Acc: 93.93% | AUC: 0.7351\n",
      "[ResNet50] Epoch 8/10 | Train Acc: 97.60% | Test Acc: 93.71% | AUC: 0.7179\n",
      "[ResNet50] Epoch 9/10 | Train Acc: 98.28% | Test Acc: 93.60% | AUC: 0.7073\n",
      "[ResNet50] Epoch 10/10 | Train Acc: 98.90% | Test Acc: 93.38% | AUC: 0.6983\n",
      "\n",
      "Training ResNet18...\n",
      "[ResNet18] Epoch 1/10 | Train Acc: 94.73% | Test Acc: 94.81% | AUC: 0.7756\n",
      "[ResNet18] Epoch 2/10 | Train Acc: 94.93% | Test Acc: 94.80% | AUC: 0.7892\n",
      "[ResNet18] Epoch 3/10 | Train Acc: 94.99% | Test Acc: 94.75% | AUC: 0.7901\n",
      "[ResNet18] Epoch 4/10 | Train Acc: 95.13% | Test Acc: 94.66% | AUC: 0.7910\n",
      "[ResNet18] Epoch 5/10 | Train Acc: 95.42% | Test Acc: 94.37% | AUC: 0.7702\n",
      "[ResNet18] Epoch 6/10 | Train Acc: 96.74% | Test Acc: 94.12% | AUC: 0.7427\n",
      "[ResNet18] Epoch 7/10 | Train Acc: 97.42% | Test Acc: 94.12% | AUC: 0.7322\n",
      "[ResNet18] Epoch 8/10 | Train Acc: 97.94% | Test Acc: 93.97% | AUC: 0.7237\n",
      "[ResNet18] Epoch 9/10 | Train Acc: 98.43% | Test Acc: 93.88% | AUC: 0.7153\n",
      "[ResNet18] Epoch 10/10 | Train Acc: 98.88% | Test Acc: 93.71% | AUC: 0.7049\n",
      "\n",
      "Training DenseNet...\n",
      "[DenseNet] Epoch 1/10 | Train Acc: 94.79% | Test Acc: 94.79% | AUC: 0.7734\n",
      "[DenseNet] Epoch 2/10 | Train Acc: 94.94% | Test Acc: 94.81% | AUC: 0.7870\n",
      "[DenseNet] Epoch 3/10 | Train Acc: 94.98% | Test Acc: 94.82% | AUC: 0.7890\n",
      "[DenseNet] Epoch 4/10 | Train Acc: 95.05% | Test Acc: 94.76% | AUC: 0.7949\n",
      "[DenseNet] Epoch 5/10 | Train Acc: 95.16% | Test Acc: 94.76% | AUC: 0.7891\n",
      "[DenseNet] Epoch 6/10 | Train Acc: 95.62% | Test Acc: 94.58% | AUC: 0.7858\n",
      "[DenseNet] Epoch 7/10 | Train Acc: 95.94% | Test Acc: 94.52% | AUC: 0.7761\n",
      "[DenseNet] Epoch 8/10 | Train Acc: 96.20% | Test Acc: 94.46% | AUC: 0.7732\n",
      "[DenseNet] Epoch 9/10 | Train Acc: 96.49% | Test Acc: 94.30% | AUC: 0.7604\n",
      "[DenseNet] Epoch 10/10 | Train Acc: 96.83% | Test Acc: 94.20% | AUC: 0.7488\n",
      "\n",
      "Training ViT...\n",
      "[ViT] Epoch 1/10 | Train Acc: 94.85% | Test Acc: 94.76% | AUC: 0.7492\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from medmnist import INFO\n",
    "from medmnist.dataset import ChestMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Dataset preparation\n",
    "dataset_name = \"chestmnist\"\n",
    "info = INFO[dataset_name]\n",
    "num_classes = len(info['label'])\n",
    "print(f\"Dataset: {dataset_name}, Num Classes: {num_classes}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "train_data = ChestMNIST(split='train', transform=transform, download=True)\n",
    "test_data = ChestMNIST(split='test', transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "vgg16_model = models.vgg16(pretrained=True)\n",
    "vgg16_model.classifier[6] = nn.Linear(vgg16_model.classifier[6].in_features, num_classes)\n",
    "\n",
    "resnet50_model = models.resnet50(pretrained=True)\n",
    "resnet50_model.fc = nn.Linear(resnet50_model.fc.in_features, num_classes)\n",
    "\n",
    "resnet18_model = models.resnet18(pretrained=True)\n",
    "resnet18_model.fc = nn.Linear(resnet18_model.fc.in_features, num_classes)\n",
    "\n",
    "densenet_model = models.densenet121(pretrained=True)\n",
    "densenet_model.classifier = nn.Linear(densenet_model.classifier.in_features, num_classes)\n",
    "\n",
    "vit_config = ViTConfig.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "vit_model = ViTForImageClassification.from_pretrained(\n",
    "    'google/vit-base-patch16-224-in21k', \n",
    "    num_labels=num_classes\n",
    ").to(device)\n",
    "\n",
    "vgg16_model, resnet50_model, resnet18_model, densenet_model = [\n",
    "    model.to(device) for model in [vgg16_model, resnet50_model, resnet18_model, densenet_model]\n",
    "]\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def extract_vit_outputs(outputs):\n",
    "    return outputs.logits if hasattr(outputs, \"logits\") else outputs\n",
    "\n",
    "\n",
    "def calculate_accuracy(outputs, targets):\n",
    "    preds = torch.sigmoid(outputs) >= 0.5\n",
    "    correct = (preds == targets).sum().float()\n",
    "    accuracy = correct / targets.numel()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def train_model(model, optimizer, criterion, scheduler, num_epochs=10, model_name=\"\"):\n",
    "    results = {\"train_acc\": [], \"test_acc\": [], \"train_loss\": [], \"test_loss\": [], \"test_auc\": []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss, train_accuracy = 0.0, 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = extract_vit_outputs(outputs)  # Handle ViT outputs\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_accuracy += calculate_accuracy(outputs, targets).item()\n",
    "        \n",
    "        results[\"train_loss\"].append(train_loss / len(train_loader))\n",
    "        results[\"train_acc\"].append(train_accuracy / len(train_loader))\n",
    "        \n",
    "        \n",
    "        model.eval()\n",
    "        test_loss, test_accuracy = 0.0, 0.0\n",
    "        all_targets, all_preds = [], []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in test_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device).float()\n",
    "                outputs = model(inputs)\n",
    "                outputs = extract_vit_outputs(outputs)  # Handle ViT outputs\n",
    "                loss = criterion(outputs, targets)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                test_accuracy += calculate_accuracy(outputs, targets).item()\n",
    "                all_preds.append(torch.sigmoid(outputs).cpu())\n",
    "                all_targets.append(targets.cpu())\n",
    "        \n",
    "        results[\"test_loss\"].append(test_loss / len(test_loader))\n",
    "        results[\"test_acc\"].append(test_accuracy / len(test_loader))\n",
    "        \n",
    "       \n",
    "        all_preds = torch.cat(all_preds).numpy()\n",
    "        all_targets = torch.cat(all_targets).numpy()\n",
    "        auc = roc_auc_score(all_targets, all_preds, average=\"macro\")\n",
    "        results[\"test_auc\"].append(auc)\n",
    "        \n",
    "        scheduler.step()\n",
    "        print(\n",
    "            f\"[{model_name}] Epoch {epoch+1}/{num_epochs} | \"\n",
    "            f\"Train Acc: {results['train_acc'][-1]*100:.2f}% | \"\n",
    "            f\"Test Acc: {results['test_acc'][-1]*100:.2f}% | \"\n",
    "            f\"AUC: {auc:.4f}\"\n",
    "        )\n",
    "    \n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    with open(f\"results/{model_name}_results.json\", \"w\") as f:\n",
    "        json.dump(results, f)\n",
    "    return results\n",
    "\n",
    "\n",
    "optimizers = {\n",
    "    \"VGG16\": optim.Adam(vgg16_model.parameters(), lr=1e-4),\n",
    "    \"ResNet50\": optim.Adam(resnet50_model.parameters(), lr=1e-4),\n",
    "    \"ResNet18\": optim.Adam(resnet18_model.parameters(), lr=1e-4),\n",
    "    \"DenseNet\": optim.Adam(densenet_model.parameters(), lr=1e-4),\n",
    "    \"ViT\": optim.Adam(vit_model.parameters(), lr=1e-4)\n",
    "}\n",
    "\n",
    "schedulers = {\n",
    "    model_name: lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    for model_name, optimizer in optimizers.items()\n",
    "}\n",
    "\n",
    "# Train All Models\n",
    "models_dict = {\n",
    "    \"VGG16\": vgg16_model,\n",
    "    \"ResNet50\": resnet50_model,\n",
    "    \"ResNet18\": resnet18_model,\n",
    "    \"DenseNet\": densenet_model,\n",
    "    \"ViT\": vit_model\n",
    "}\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models_dict.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    try:\n",
    "        results[model_name] = train_model(\n",
    "            model, optimizers[model_name], criterion, schedulers[model_name], num_epochs=10, model_name=model_name\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while training {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Visualization\n",
    "def plot_results(results, metric, ylabel):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for model_name, result in results.items():\n",
    "        if metric in result:\n",
    "            plt.plot(result[metric], label=model_name)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f'{ylabel} vs Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Plot Results\n",
    "metrics = {\"train_acc\": \"Training Accuracy\", \"test_acc\": \"Testing Accuracy\",\n",
    "           \"train_loss\": \"Training Loss\", \"test_loss\": \"Testing Loss\", \"test_auc\": \"Testing AUC\"}\n",
    "\n",
    "for metric, ylabel in metrics.items():\n",
    "    plot_results(results, metric, ylabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-02T21:37:03.892023Z",
     "iopub.status.busy": "2024-12-02T21:37:03.891390Z",
     "iopub.status.idle": "2024-12-02T21:37:15.004703Z",
     "shell.execute_reply": "2024-12-02T21:37:15.003673Z",
     "shell.execute_reply.started": "2024-12-02T21:37:03.891986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medmnist\n",
      "  Downloading medmnist-3.0.2-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from medmnist) (1.26.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from medmnist) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from medmnist) (1.2.2)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.23.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from medmnist) (4.66.4)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from medmnist) (10.3.0)\n",
      "Collecting fire (from medmnist)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from medmnist) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from medmnist) (0.19.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->medmnist) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->medmnist) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (1.14.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (3.3)\n",
      "Requirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (2024.5.22)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (21.3)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->medmnist) (0.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->medmnist) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->medmnist) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->medmnist) (2024.6.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->medmnist) (3.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->medmnist) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->medmnist) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->medmnist) (1.3.0)\n",
      "Downloading medmnist-3.0.2-py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114248 sha256=d2dc4e6fbf853bb10723d60c009e8aa9ea47325e46c68f6886ba4bab50652989\n",
      "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
      "Successfully built fire\n",
      "Installing collected packages: fire, medmnist\n",
      "Successfully installed fire-0.7.0 medmnist-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install medmnist"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
